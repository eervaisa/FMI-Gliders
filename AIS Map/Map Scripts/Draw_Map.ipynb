{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML \n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "\n",
    "import folium\n",
    "import folium.plugins as plugins\n",
    "import altair as alt\n",
    "from branca.element import Template, MacroElement\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, LineString, Point\n",
    "\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "from ipynb.fs.defs.Digitraffic_To_SQLite import update_meta_table, get_latest_meta_update_timestamp, classify_regions, append_table, delete_duplicate_rows, convert_coordinates_ddmm_to_dddd # Extended comment in cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quote from ipynb readme:\n",
    "\n",
    "Definitions only import\n",
    "\n",
    "Sometimes your notebook has been used as a way to run an analysis or other computation, and you only want to import the functions / classes defined in it - and not the extra statements you have in there. This can be accomplished via ipynb.fs.defs.\n",
    "\n",
    "If you have a notebook file named server.ipynb, and do:\n",
    "\n",
    "import ipynb.fs.defs.server\n",
    "\n",
    "It'll only execute and make available the following parts of the code in server.ipynb:\n",
    "\n",
    "    class definitions\n",
    "    def function definitions\n",
    "    import statements\n",
    "    Assignment statements where the variables being assigned to are ALL_CAPS. These are assumed to be constants.\n",
    "\n",
    "This skips most computational work and brings in your definitions only, making it easy to reuse functions / classes across similar analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection(db_file):\n",
    "    '''Create a database connection to a SQLite database'''\n",
    "\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    \n",
    "    return conn\n",
    "\n",
    "def check_missing_meta(db_connection, ships_df):\n",
    "    '''Check if any metadata is missing and update if necessary'''\n",
    "\n",
    "    no_meta = ships_df[\"metaUpdateTimestamp\"].isna()\n",
    "    if(any(no_meta)):\n",
    "        no_meta_ships = ships_df[no_meta.values][\"mmsi\"]\n",
    "        no_meta_ships_string = \", \".join(no_meta_ships.apply(str))\n",
    "\n",
    "        # Update meta table from API\n",
    "        update_meta_table(db_connection, get_latest_meta_update_timestamp(db_connection))\n",
    "\n",
    "        # Query missing metadata\n",
    "        query = f\"SELECT * FROM meta WHERE mmsi IN ({no_meta_ships_string})\"\n",
    "        meta_df = pd.read_sql_query(query, db_connection)\n",
    "\n",
    "        if(meta_df.empty):\n",
    "            print(\"Some metadata still missing after update, try again later\")\n",
    "            return ships_df\n",
    "\n",
    "        # Make mmsi into the index for updating\n",
    "        meta_df.set_index('mmsi', inplace = True)\n",
    "        ships_df.set_index('mmsi', inplace = True)\n",
    "\n",
    "        # Fill missing data\n",
    "        ships_df.update(meta_df)\n",
    "\n",
    "        # Make mmsi into a column again\n",
    "        ships_df.reset_index(inplace = True)\n",
    "\n",
    "    return ships_df\n",
    "\n",
    "def load_data(db_connection, since):\n",
    "    '''Load and merge data from a SQLite database into a dataframe'''\n",
    "\n",
    "    path_since = since - timedelta(hours=3).seconds*1000\n",
    "\n",
    "    # Query latest locations for each mmsi in locations table,\n",
    "    # taking only recently updated rows,\n",
    "    # then left join with meta table\n",
    "    \"\"\" query = (\"SELECT * FROM (\" \n",
    "                \"SELECT *, ROW_NUMBER() OVER(PARTITION BY mmsi ORDER BY locUpdateTimestamp DESC) AS rownum FROM locations\"\n",
    "            \") latest_locs \"\n",
    "            \"LEFT JOIN meta ON latest_locs.mmsi = meta.mmsi \"\n",
    "            \"WHERE latest_locs.rownum = 1 \"\n",
    "            f\"AND locUpdateTimestamp > {since}\") \"\"\"\n",
    "    \n",
    "    query = (\"SELECT * FROM locations \"\n",
    "            \"LEFT JOIN meta ON locations.mmsi = meta.mmsi \"\n",
    "            f\"WHERE locations.mmsi IN \"\n",
    "                \"(SELECT mmsi from locations \"\n",
    "               f\"WHERE locUpdateTimestamp > {since}) \"\n",
    "            f\"AND locUpdateTimestamp > {path_since}\")\n",
    "\n",
    "    ships_df = pd.read_sql_query(query, db_connection)\n",
    "\n",
    "    ships_df = ships_df.loc[:,~ships_df.columns.duplicated()] # If mmsi column duplicates from missing values in meta, drop the extra column\n",
    "\n",
    "    # Limit taken path length by time since last update\n",
    "    # ships_df = ships_df[ships_df.groupby('mmsi')['locUpdateTimestamp'].transform('max')-path_since < ships_df['locUpdateTimestamp']]\n",
    "\n",
    "    # Create a column for the path in a new dataframe\n",
    "    ship_paths_df = ships_df[[\"mmsi\", \"latitude\", \"longitude\"]].copy()\n",
    "    ship_paths_df.drop_duplicates(inplace = True)\n",
    "    ship_paths_df[\"coords\"] = ship_paths_df[[\"latitude\", \"longitude\"]].values.tolist()\n",
    "    ship_paths_df = ship_paths_df.groupby(\"mmsi\").apply(lambda row: list(row[\"coords\"]), include_groups=False).reset_index()\n",
    "    ship_paths_df.rename(columns = {0: \"path\"}, inplace = True)\n",
    "\n",
    "    # Take only latest location and add path column\n",
    "    ships_df = ships_df.loc[ships_df.groupby([\"mmsi\"])[\"locUpdateTimestamp\"].idxmax()]\n",
    "    ships_df = ships_df.merge(ship_paths_df, how='left')\n",
    "\n",
    "    # Check for missing metadata and add it if necessary\n",
    "    ships_df = check_missing_meta(db_connection, ships_df)\n",
    "\n",
    "    # Fix formatting and naming of time columns\n",
    "    ships_df[\"metaUpdatetime\"]  = pd.to_datetime(ships_df[\"metaUpdateTimestamp\"],unit=\"ms\")\n",
    "    ships_df[\"locUpdatetime\"]   = pd.to_datetime(ships_df[\"locUpdateTimestamp\"], unit=\"ms\")\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    # ships_df = ships_df.drop([\"metaUpdateTimestamp\", \"locUpdateTimestamp\", \"rownum\"], axis=1)\n",
    "    ships_df = ships_df.drop([\"metaUpdateTimestamp\", \"locUpdateTimestamp\"], axis=1)\n",
    "\n",
    "    return ships_df\n",
    "\n",
    "def save_dangerous_ship_data(ships_df, glider_name, glider_latest_loc, db_connection):\n",
    "    '''Update SQLite database with dangerous ship data'''\n",
    "\n",
    "    # TODO: Consider if:\n",
    "    #       We should convert time back to timestamp for database interaction\n",
    "    #       Retrieve and save rows from before threat classification (when still \"yellow\")\n",
    "    #       We want more data about glider\n",
    "    #       Currently chance for duplicating same ship for multiple gliders, and if that matters\n",
    "\n",
    "    dangerous_ships = ships_df.loc[(ships_df['threat_class'].isin([2,3,5]))].copy()\n",
    "\n",
    "    if(not dangerous_ships.empty):\n",
    "\n",
    "        # Set the colours we would draw the markers with for easier readability\n",
    "        dangerous_ships[\"class_colour\"] = \"#8ed6ff\"\n",
    "        dangerous_ships.loc[(dangerous_ships['threat_class'] == 1), \n",
    "                            \"class_colour\"] = \"yellow\"\n",
    "        dangerous_ships.loc[(dangerous_ships['threat_class'] == 2), \n",
    "                            \"class_colour\"] = \"orange\"\n",
    "        dangerous_ships.loc[(dangerous_ships['threat_class'] == 3), \n",
    "                            \"class_colour\"] = \"red\"\n",
    "        dangerous_ships.loc[(dangerous_ships['threat_class'] == 4), \n",
    "                            \"class_colour\"] = \"grey\"\n",
    "        dangerous_ships.loc[(dangerous_ships['threat_class'] == 5), \n",
    "                            \"class_colour\"] = \"purple\"\n",
    "\n",
    "        dangerous_ships['glider_name'] = glider_name\n",
    "        dangerous_ships['glider_latest_lat'] = glider_latest_loc[0]\n",
    "        dangerous_ships['glider_latest_lon'] = glider_latest_loc[1]\n",
    "        dangerous_ships.drop(columns=['path', 'range', 'tooltip_html', 'threat_class', 'max_threat_class'], inplace=True)\n",
    "\n",
    "        append_table(db_connection, dangerous_ships, \"threats\")\n",
    "        delete_duplicate_rows(db_connection, \"threats\", \", \".join(list(dangerous_ships.columns)))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glider data interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_web_json(url):\n",
    "    '''Read json-file from url'''\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        data = r.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return {}\n",
    "    return(data)\n",
    "\n",
    "def read_json(file):\n",
    "    '''Read local json-file'''\n",
    "    try:\n",
    "        f = open(file, \"r\")\n",
    "    except IOError as e:\n",
    "        print(e)\n",
    "        return {}\n",
    "    else:\n",
    "        data = json.loads(f.read())\n",
    "        f.close()\n",
    "    return(data)\n",
    "\n",
    "def load_glider_sensors(interesting_sensors):\n",
    "    '''Read data from glider'''\n",
    "    pathData = read_json('../Map Data/Gliders/JSONs/current_positions.json')\n",
    "    glider_names = list(pathData.keys())\n",
    "\n",
    "    gliders_df = pd.DataFrame()\n",
    "    for glider_name in glider_names:\n",
    "        glider_df = pd.DataFrame.from_dict(pathData[glider_name])\n",
    "        glider_df[\"glider_name\"] = str.capitalize(glider_name)\n",
    "        gliders_df = pd.concat([gliders_df, glider_df], ignore_index=True)\n",
    "    \n",
    "    if(gliders_df.empty):\n",
    "        return None, gliders_df, interesting_sensors\n",
    "\n",
    "    gliders_df[\"datetime\"] = pd.to_datetime(gliders_df[\"datetime\"], format='%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "    # Explode nested dicts into columns\n",
    "    gliders_df = gliders_df.join(pd.DataFrame(gliders_df.pop('location').values.tolist()))\n",
    "\n",
    "    sensors_df = pd.DataFrame(gliders_df.pop('sensors').values.tolist())\n",
    "    \n",
    "    # Use only sensors also in dataframe:\n",
    "    interesting_sensors = list(set(sensors_df.columns).intersection(set(interesting_sensors)))\n",
    "\n",
    "    sensors_df = sensors_df[interesting_sensors]\n",
    "    gliders_df = gliders_df.join(sensors_df)\n",
    "\n",
    "    return glider_names, gliders_df, interesting_sensors\n",
    "\n",
    "def load_glider_waypoints(glider_names, gliders_latest_loc):\n",
    "    '''Read waypoint plan data'''\n",
    "\n",
    "    glider_waypoints = read_json('../Map Data/Gliders/JSONs/glider_waypoints.json')\n",
    "    wpt_glider_names = list(glider_waypoints.keys())\n",
    "    gliders_wpt_df = pd.DataFrame()\n",
    "    \n",
    "    for glider_name in glider_names:\n",
    "        # Add data into dataframe\n",
    "        glider_wpt_df = pd.DataFrame()\n",
    "        if(glider_name in wpt_glider_names):\n",
    "            glider_wpt_df['longitude'] = [coords[0] for coords in glider_waypoints[glider_name]]\n",
    "            glider_wpt_df['latitude']  = [coords[1] for coords in glider_waypoints[glider_name]]\n",
    "            glider_wpt_df['glider_name'] = str.capitalize(glider_name)\n",
    "        else:\n",
    "            glider_wpt_df = gliders_latest_loc.loc[gliders_latest_loc[\"glider_name\"] == str.capitalize(glider_name), \n",
    "                                               [\"glider_name\", \"latitude\", \"longitude\"]].copy()\n",
    "            glider_wpt_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        gliders_wpt_df = pd.concat([gliders_wpt_df, glider_wpt_df], ignore_index=True)\n",
    "\n",
    "    return gliders_wpt_df\n",
    "    \n",
    "\n",
    "def load_glider_data(interesting_sensors):\n",
    "    ''' Load glider data and reformat for map drawing'''\n",
    "\n",
    "    glider_names, gliders_df, interesting_sensors = load_glider_sensors(interesting_sensors)\n",
    "\n",
    "    if (gliders_df.empty):\n",
    "        return None, interesting_sensors\n",
    "\n",
    "    gliders_latest_loc = gliders_df.loc[gliders_df.groupby([\"glider_name\"])[\"datetime\"].idxmax()]\n",
    "\n",
    "    gliders_wpt_df = load_glider_waypoints(glider_names, gliders_latest_loc)\n",
    "\n",
    "    gliders_wpt_df = classify_regions(gliders_wpt_df, \"latitude\", \"longitude\", \"glider_region\")\n",
    "\n",
    "    glider_names = [str.capitalize(glider_name) for glider_name in glider_names]\n",
    "\n",
    "    gliders_regions = gliders_wpt_df[[\"glider_name\", \"glider_region\"]].drop_duplicates()\n",
    "\n",
    "    glider_data = {\"glider_names\":       glider_names,\n",
    "                   \"gliders_df\":         gliders_df,\n",
    "                   \"gliders_wpt_df\":     gliders_wpt_df,\n",
    "                   \"gliders_latest_loc\": gliders_latest_loc,\n",
    "                   \"gliders_regions\":    gliders_regions}\n",
    "\n",
    "    return glider_data, interesting_sensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coordinate calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(point1, point2):\n",
    "    '''Haversine distance between two points, points in gps coordinates'''\n",
    "    \n",
    "    R = 6373.0\n",
    "    lat1 = math.radians(point1[0])\n",
    "    lon1 = math.radians(point1[1])\n",
    "    lat2 = math.radians(point2[0])\n",
    "    lon2 = math.radians(point2[1])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = (math.sin(dlat/2))**2 + math.cos(lat1) * math.cos(lat2) * (math.sin(dlon/2))**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "def get_endpoint(lat1,lon1,bearing,dist):\n",
    "    '''Find end point with start coordinates, bearing & distance'''\n",
    "    \n",
    "    R = 6371                     #Radius of the Earth\n",
    "\n",
    "    d = dist\n",
    "    \n",
    "    brng = math.radians(bearing) #Convert degrees to radians\n",
    "    \n",
    "    lat1 = math.radians(lat1)    #Current lat point converted to radians\n",
    "    lon1 = math.radians(lon1)    #Current long point converted to radians\n",
    "\n",
    "    lat2 = math.asin(math.sin(lat1)*math.cos(d/R) + math.cos(lat1)*math.sin(d/R)*math.cos(brng))\n",
    "    lon2 = lon1 + math.atan2(math.sin(brng)*math.sin(d/R)*math.cos(lat1),math.cos(d/R)-math.sin(lat1)*math.sin(lat2))\n",
    "    lat2 = math.degrees(lat2)\n",
    "    lon2 = math.degrees(lon2)\n",
    "    \n",
    "    return [lat2,lon2]\n",
    "\n",
    "def get_path(coords, sog, cog, rot):\n",
    "    '''Find path coordinates based on speed, course and rotation'''\n",
    "    # sog is speed over ground in knots (= 1.852 km/h). Most ships move at 10-20 knots.\n",
    "    # rot = 4.733*SQRT(ROT[IND]) where ROT[IND] is the Rate of Turn degrees per minute. +(-)127 == >(<-)720 deg/min\n",
    "    \n",
    "    path = [coords]\n",
    "    # If ship's speed is undefined or zero, just give up\n",
    "    if(sog==0 | pd.isna(sog)):\n",
    "        return [path,0]\n",
    "\n",
    "    interval_duration = 1  # Minutes\n",
    "    path_duration     = 60 # Minutes\n",
    "    latitude  = coords[0]\n",
    "    longitude = coords[1]\n",
    "    bearing = cog\n",
    "    rotation = 0 if pd.isna(rot) else rot\n",
    "\n",
    "    interval_distance = sog/(60/interval_duration)*1.852                        # Convert nautical miles to km (knots to km/h) and duration from min to h\n",
    "    interval_rotation = (rotation/4.733)**2*interval_duration*np.sign(rotation) # Convert to deg/min\n",
    "\n",
    "    radius = interval_distance*(path_duration/interval_duration)*1000 # Leaflet's L.Circle uses meters (as float) for radius\n",
    "    if(pd.isna(radius)):\n",
    "        radius = 0\n",
    "\n",
    "    # If ship rotates too fast or course is undefined, simply draw a circle based on speed\n",
    "    if((abs(interval_rotation) >= 90) | pd.isna(cog)):\n",
    "        return path, radius\n",
    "\n",
    "    for i in range(path_duration//interval_duration-1):\n",
    "        path.append(get_endpoint(latitude,longitude,bearing,interval_distance))\n",
    "        latitude = path[i+1][0]\n",
    "        longitude = path[i+1][1]\n",
    "\n",
    "        # Limit turning to a U-turn\n",
    "        if(round(abs(bearing - cog),2) >= 180):\n",
    "            bearing = (cog + 180) % 360\n",
    "        else:\n",
    "            bearing = bearing + interval_rotation\n",
    "\n",
    "    return path, radius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ship data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_ship_types(ships_df):\n",
    "    '''Translate ship type to string'''\n",
    "    \n",
    "    ships_df[\"shipTypeString\"] = \"None\"\n",
    "    ships_df.loc[(ships_df['shipType'] >= 20) & (ships_df['shipType'] <= 29), \"shipTypeString\"] = \"Wing in ground\"\n",
    "    ships_df.loc[(ships_df['shipType'] == 30),                                \"shipTypeString\"] = \"Fishing\"\n",
    "    ships_df.loc[(ships_df['shipType'] >= 31) & (ships_df['shipType'] <= 32), \"shipTypeString\"] = \"Towing\"\n",
    "    ships_df.loc[(ships_df['shipType'] == 33),                                \"shipTypeString\"] = \"Dredging or underwater ops\"\n",
    "    ships_df.loc[(ships_df['shipType'] == 34),                                \"shipTypeString\"] = \"Diving ops\"\n",
    "    ships_df.loc[(ships_df['shipType'] == 35),                                \"shipTypeString\"] = \"Military ops\"\n",
    "    ships_df.loc[(ships_df['shipType'] == 36),                                \"shipTypeString\"] = \"Sailing\"\n",
    "    ships_df.loc[(ships_df['shipType'] == 37),                                \"shipTypeString\"] = \"Pleasure Craft\"\n",
    "    ships_df.loc[(ships_df['shipType'] >= 40) & (ships_df['shipType'] <= 49), \"shipTypeString\"] = \"High speed craft\"\n",
    "    ships_df.loc[(ships_df['shipType'] == 50),                                \"shipTypeString\"] = \"Pilot Vessel\"\n",
    "    ships_df.loc[(ships_df['shipType'] == 51),                                \"shipTypeString\"] = \"Search and Rescue vessel\"\n",
    "    ships_df.loc[(ships_df['shipType'] == 52),                                \"shipTypeString\"] = \"Tug\"\n",
    "    ships_df.loc[(ships_df['shipType'] == 53),                                \"shipTypeString\"] = \"Port Tender\"\n",
    "    ships_df.loc[(ships_df['shipType'] == 54),                                \"shipTypeString\"] = \"Anti-pollution equipment\"\n",
    "    ships_df.loc[(ships_df['shipType'] == 55),                                \"shipTypeString\"] = \"Law Enforcement\"\n",
    "    ships_df.loc[(ships_df['shipType'] >= 56) & (ships_df['shipType'] <= 57), \"shipTypeString\"] = \"Spare - Local Vessel\"\n",
    "    ships_df.loc[(ships_df['shipType'] == 58),                                \"shipTypeString\"] = \"Law Enforcement\"\n",
    "    ships_df.loc[(ships_df['shipType'] == 59),                                \"shipTypeString\"] = \"Noncombatant\"\n",
    "    ships_df.loc[(ships_df['shipType'] >= 60) & (ships_df['shipType'] <= 69), \"shipTypeString\"] = \"Passenger\"\n",
    "    ships_df.loc[(ships_df['shipType'] >= 70) & (ships_df['shipType'] <= 79), \"shipTypeString\"] = \"Cargo\"\n",
    "    ships_df.loc[(ships_df['shipType'] >= 80) & (ships_df['shipType'] <= 89), \"shipTypeString\"] = \"Tanker\"\n",
    "    ships_df.loc[(ships_df['shipType'] >= 90) & (ships_df['shipType'] <= 99), \"shipTypeString\"] = \"Other\"\n",
    "    \n",
    "    return ships_df\n",
    "\n",
    "def process_no_gliders_ship_data(ships_df):\n",
    "    '''Prepare data for drawing ship markers when there are no active gliders'''\n",
    "\n",
    "    # Predict ship movement\n",
    "    # NOTE: GeoPandas uses LonLat, so all intersect checks have to as well\n",
    "    # ships_df[['path', 'range']]  = ships_df.apply(lambda row: get_path([row['latitude'],row['longitude']],row['sog'],row['cog'],row['rot']), axis=1, result_type='expand')\n",
    "    ships_df[['predicted_path', 'range']]  = ships_df.apply(lambda row: get_path([row['latitude'],row['longitude']],row['sog'],row['cog'],row['rot']), axis=1, result_type='expand')\n",
    "    ships_df['path'] = ships_df['path'] + ships_df['predicted_path']\n",
    "    ships_df.drop(columns=['predicted_path'], inplace=True)\n",
    "    ship_ranges = gpd.GeoDataFrame(ships_df, geometry=gpd.points_from_xy(ships_df.longitude, ships_df.latitude), crs=\"EPSG:4979\") # Map projection units in degrees\n",
    "    ship_ranges = ship_ranges.to_crs(\"EPSG:3857\")         # Map projection units in meters for setting circle radius\n",
    "    ship_ranges = ship_ranges.buffer(ships_df['range'])\n",
    "    ship_ranges = ship_ranges.to_crs(\"EPSG:4979\")         # Map projection units in degrees for testing intersection\n",
    "\n",
    "    # Translate ship type to string\n",
    "    ships_df = translate_ship_types(ships_df)\n",
    "\n",
    "    # For consistency in presentation\n",
    "    ships_df[[\"name\",\"callSign\",\"shipTypeString\",\"destination\",\"eta\"]] = ships_df[[\"name\",\"callSign\",\"shipTypeString\",\"destination\",\"eta\"]].fillna(\"\")\n",
    "\n",
    "    ships_df['tooltip_html'] = ships_df.apply(lambda ship: '</span></p><p style=\"text-align:left;\">'.join(\n",
    "            ['<p style=\"text-align:left;\"> ' + \n",
    "             'Name: <span style=\"float:right;\">'          + ship['name'],\n",
    "             'Callsign: <span style=\"float:right;\">'      + ship['callSign'],\n",
    "             'Ship type: <span style=\"float:right;\">'     + ship['shipTypeString'],\n",
    "             'Draught (m): <span style=\"float:right;\">'   + str(ship['draught']/10).replace('nan',''),\n",
    "             'Location: <span style=\"float:right;\">'      + str(round(ship['latitude'], 3)) + \" / \" + str(round(ship['longitude'], 3)),\n",
    "             'Speed (knots): <span style=\"float:right;\">' + str(ship['sog']).replace('nan',''),\n",
    "             'Course (deg): <span style=\"float:right;\">'  + str(ship['cog']).replace('nan',''),\n",
    "             'Destination: <span style=\"float:right;\">'   + ship['destination'],\n",
    "             'ETA: <span style=\"float:right;\">'           + ship['eta'],\n",
    "             'Last updated: <span style=\"float:right;\">'  + ship['locUpdatetime'].strftime(\"%Y-%m-%d %H:%M:%S\").replace('NaT','') + \n",
    "             \"</p>\"]), axis=1)\n",
    "\n",
    "    # After creating tooltips but before creating markers we want to fill NAs\n",
    "    ships_df[['cog', 'sog']] = ships_df[['cog', 'sog']].fillna(0) \n",
    "    \n",
    "    return ships_df\n",
    "\n",
    "def classify_ships(ships_df, ship_ranges, vip_ships, glider_latest_loc, glider_regions, glider_wpt_line):\n",
    "    '''Classify ships based on threat'''\n",
    "\n",
    "    ships_df['distance_from_glider'] = ships_df.apply(lambda ship: haversine_distance([ship['latitude'],ship['longitude']], glider_latest_loc), axis=1)\n",
    "\n",
    "    # Default/unclassified\n",
    "    ships_df['threat_class'] = 0\n",
    "\n",
    "    # Ships in - or with destination in - the same region as glider\n",
    "    ships_df.loc[ships_df[['shipRegion', \n",
    "                          'destinationOneRegion', \n",
    "                          'destinationTwoRegion', \n",
    "                          'destinationThreeRegion']].isin(glider_regions).any(axis=1), \"threat_class\"] = 1\n",
    "\n",
    "    # Check for ships going through glider regions\n",
    "    if(\"Bothnian Sea\" in glider_regions):\n",
    "        ships_df.loc[(ships_df['shipRegion'].isin([\"Baltic Sea\", \"Archipelago Sea\", \"Gulf of Finland\", \"Saimaa and Laatokka\"])) & \n",
    "                     (ships_df[['destinationOneRegion', \n",
    "                                'destinationTwoRegion', \n",
    "                                'destinationThreeRegion']].isin([\"Bothnian Bay\"]).any(axis=1)), \n",
    "                    \"threat_class\"] = 1\n",
    "        ships_df.loc[(ships_df['shipRegion'].isin([\"Bothnian Bay\"])) & \n",
    "                     (ships_df[['destinationOneRegion', \n",
    "                                'destinationTwoRegion', \n",
    "                                'destinationThreeRegion']].isin([\"Baltic Sea\", \"Archipelago Sea\", \"Gulf of Finland\", \"Saimaa and Laatokka\"]).any(axis=1)), \n",
    "                    \"threat_class\"] = 1\n",
    "    \n",
    "    if(\"Archipelago Sea\" in glider_regions):\n",
    "        ships_df.loc[(ships_df['shipRegion'].isin([\"Baltic Sea\", \"Gulf of Finland\", \"Saimaa and Laatokka\"])) & \n",
    "                     (ships_df[['destinationOneRegion', \n",
    "                                'destinationTwoRegion', \n",
    "                                'destinationThreeRegion']].isin([\"Bothnian Bay\", \"Bothnian Sea\"]).any(axis=1)), \n",
    "                    \"threat_class\"] = 1\n",
    "        ships_df.loc[(ships_df['shipRegion'].isin([\"Bothnian Bay\", \"Bothnian Sea\"])) & \n",
    "                     (ships_df[['destinationOneRegion', \n",
    "                                'destinationTwoRegion', \n",
    "                                'destinationThreeRegion']].isin([\"Baltic Sea\", \"Gulf of Finland\", \"Saimaa and Laatokka\"]).any(axis=1)), \n",
    "                    \"threat_class\"] = 1\n",
    "        \n",
    "    if(\"Gulf of Finland\" in glider_regions):\n",
    "        ships_df.loc[(ships_df['shipRegion'].isin([\"Saimaa and Laatokka\"])) & \n",
    "                     (ships_df[['destinationOneRegion', \n",
    "                                'destinationTwoRegion', \n",
    "                                'destinationThreeRegion']].isin([\"Baltic Sea\", \"Archipelago Sea\", \"Bothnian Bay\", \"Bothnian Sea\"]).any(axis=1)), \n",
    "                    \"threat_class\"] = 1\n",
    "        ships_df.loc[(ships_df['shipRegion'].isin([\"Baltic Sea\", \"Archipelago Sea\", \"Bothnian Bay\", \"Bothnian Sea\"])) & \n",
    "                     (ships_df[['destinationOneRegion', \n",
    "                                'destinationTwoRegion', \n",
    "                                'destinationThreeRegion']].isin([\"Saimaa and Laatokka\"]).any(axis=1)), \n",
    "                    \"threat_class\"] = 1\n",
    "\n",
    "    # Ships that intersect glider plan\n",
    "    # TODO: Consider marking only those that also don't intersect past path?\n",
    "    #       dangerous with sharp turns though...\n",
    "    ships_df.loc[(ships_df['range'] > 0) & (ship_ranges.intersects(glider_wpt_line)), \"threat_class\"] = 2\n",
    "\n",
    "    # Ships whose range intersects glider's location\n",
    "    ships_df.loc[(ships_df['range'] > 0) & (ships_df['distance_from_glider']*1000 < ships_df['range']), \"threat_class\"] = 3\n",
    "\n",
    "    # Stationary ships\n",
    "    ships_df.loc[(ships_df['sog'] == 0), \"threat_class\"] = 4\n",
    "\n",
    "    # Ships within 10km\n",
    "    ships_df.loc[(ships_df['distance_from_glider'] < 10), \"threat_class\"] = 5\n",
    "\n",
    "    # VIP ships\n",
    "    ships_df.loc[(ships_df['mmsi'].isin(vip_ships)), \"threat_class\"] = 99\n",
    "\n",
    "    # Save the highest threat class so far for map drawing\n",
    "    ships_df.loc[(ships_df['max_threat_class'] < ships_df['threat_class']), \n",
    "                 \"max_threat_class\"] = ships_df['threat_class']\n",
    "    \n",
    "    return ships_df\n",
    "\n",
    "def process_ship_data(ships_df, glider_data, vip_ships, db_connection):\n",
    "    '''Prepare data for drawing ship markers'''\n",
    "\n",
    "    # Predict ship movement\n",
    "    # NOTE: GeoPandas uses LonLat, so all intersect checks have to as well\n",
    "    # ships_df[['path', 'range']]  = ships_df.apply(lambda row: get_path([row['latitude'],row['longitude']],row['sog'],row['cog'],row['rot']), axis=1, result_type='expand')\n",
    "    ships_df[['predicted_path', 'range']]  = ships_df.apply(lambda row: get_path([row['latitude'],row['longitude']],row['sog'],row['cog'],row['rot']), axis=1, result_type='expand')\n",
    "    ships_df['path'] = ships_df['path'] + ships_df['predicted_path']\n",
    "    ships_df.drop(columns=['predicted_path'], inplace=True)\n",
    "    ship_ranges = gpd.GeoDataFrame(ships_df, geometry=gpd.points_from_xy(ships_df.longitude, ships_df.latitude), crs=\"EPSG:4326\") # Map projection units in degrees\n",
    "    ship_ranges = ship_ranges.to_crs(\"EPSG:32634\")         # Map projection units in meters for setting circle radius\n",
    "    ship_ranges = ship_ranges.buffer(ships_df['range'])\n",
    "    ship_ranges = ship_ranges.to_crs(\"EPSG:4326\")         # Map projection units in degrees for testing intersection\n",
    "\n",
    "    # Unpack glider_data dict for readability\n",
    "    glider_names       = glider_data[\"glider_names\"]\n",
    "    gliders_regions    = glider_data[\"gliders_regions\"]\n",
    "    gliders_wpt_df     = glider_data[\"gliders_wpt_df\"]\n",
    "    gliders_latest_loc = glider_data[\"gliders_latest_loc\"]\n",
    "\n",
    "    # Translate ship type to string\n",
    "    ships_df = translate_ship_types(ships_df)\n",
    "\n",
    "    # For consistency in presentation\n",
    "    ships_df[[\"name\",\"callSign\",\"shipTypeString\",\"destination\",\"eta\"]] = ships_df[[\"name\",\"callSign\",\"shipTypeString\",\"destination\",\"eta\"]].fillna(\"\")\n",
    "\n",
    "    ships_df['tooltip_html'] = ships_df.apply(lambda ship: '</span></p><p style=\"text-align:left;\">'.join(\n",
    "            ['<p style=\"text-align:left;\"> ' + \n",
    "             'Name: <span style=\"float:right;\">'          + ship['name'],\n",
    "             'Callsign: <span style=\"float:right;\">'      + ship['callSign'],\n",
    "             'Ship type: <span style=\"float:right;\">'     + ship['shipTypeString'],\n",
    "             'Draught (m): <span style=\"float:right;\">'   + str(ship['draught']/10).replace('nan',''),\n",
    "             'Location: <span style=\"float:right;\">'      + str(round(ship['latitude'], 3)) + \" / \" + str(round(ship['longitude'], 3)),\n",
    "             'Speed (knots): <span style=\"float:right;\">' + str(ship['sog']).replace('nan',''),\n",
    "             'Course (deg): <span style=\"float:right;\">'  + str(ship['cog']).replace('nan',''),\n",
    "             'Destination: <span style=\"float:right;\">'   + ship['destination'],\n",
    "             'ETA: <span style=\"float:right;\">'           + ship['eta'],\n",
    "             'Last updated: <span style=\"float:right;\">'  + ship['locUpdatetime'].strftime(\"%Y-%m-%d %H:%M:%S\").replace('NaT','') + \n",
    "             \"</p>\"]), axis=1)\n",
    "\n",
    "    ships_df['max_threat_class'] = 0\n",
    "\n",
    "    for glider_name in glider_names:\n",
    "        glider_latest_loc = gliders_latest_loc[[\"latitude\",\"longitude\"]].loc[gliders_latest_loc[\"glider_name\"] == glider_name].values.tolist()[0]\n",
    "        glider_regions = list(gliders_regions[\"glider_region\"].loc[gliders_regions[\"glider_name\"] == glider_name])\n",
    "        glider_wpt_df = gliders_wpt_df.loc[gliders_wpt_df[\"glider_name\"] == glider_name]\n",
    "\n",
    "        # NOTE: GeoPandas uses LonLat, so all intersect checks have to as well\n",
    "        glider_wpt_line = glider_wpt_df[[\"longitude\", \"latitude\"]].values.tolist()\n",
    "        if(len(glider_wpt_line) > 1):\n",
    "            glider_wpt_line = LineString(glider_wpt_line)\n",
    "        else:\n",
    "            glider_wpt_line = Point(glider_wpt_line)\n",
    "\n",
    "        ships_df = classify_ships(ships_df, ship_ranges, vip_ships, glider_latest_loc, glider_regions, glider_wpt_line)\n",
    "        \n",
    "        # Write dangerous ships into a sqlite table\n",
    "        save_dangerous_ship_data(ships_df, glider_name, glider_latest_loc, db_connection)\n",
    "\n",
    "    # Set the colours we want to draw the markers with\n",
    "    ships_df[\"max_class_colour\"] = \"#8ed6ff\"\n",
    "    ships_df.loc[(ships_df['max_threat_class'] == 1), \n",
    "                 \"max_class_colour\"] = \"yellow\"\n",
    "    ships_df.loc[(ships_df['max_threat_class'] == 2), \n",
    "                 \"max_class_colour\"] = \"orange\"\n",
    "    ships_df.loc[(ships_df['max_threat_class'] == 3), \n",
    "                 \"max_class_colour\"] = \"red\"\n",
    "    ships_df.loc[(ships_df['max_threat_class'] == 4), \n",
    "                 \"max_class_colour\"] = \"grey\"\n",
    "    ships_df.loc[(ships_df['max_threat_class'] == 5), \n",
    "                 \"max_class_colour\"] = \"purple\"\n",
    "    ships_df.loc[(ships_df['max_threat_class'] == 99), \n",
    "                 \"max_class_colour\"] = \"#26f018\"\n",
    "    \n",
    "    # Drop now unnecessary classification columns\n",
    "    ships_df.drop(columns=['threat_class', 'max_threat_class'], inplace=True)\n",
    "\n",
    "    # After creating tooltips but before creating markers we want to fill NAs\n",
    "    ships_df[['cog', 'sog']] = ships_df[['cog', 'sog']].fillna(0) \n",
    "    \n",
    "    return ships_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_no_gliders_ship_markers(map, ships_df, vip_ships):\n",
    "    '''Add markers for ships on the map when there are no active gliders'''\n",
    "\n",
    "    # Create layers for ship markers\n",
    "    # For performance reasons we don't show all at once by default\n",
    "    baltic_sea_ship_layer      = folium.map.FeatureGroup(name = \"Baltic Sea\", show = False)\n",
    "    bothnian_bay_ship_layer    = folium.map.FeatureGroup(name = \"Bothnian Bay\", show = False)\n",
    "    bothnian_sea_ship_layer    = folium.map.FeatureGroup(name = \"Bothnian Sea\")\n",
    "    archipelago_sea_ship_layer = folium.map.FeatureGroup(name = \"Archipelago Sea\")\n",
    "    gulf_of_finland_ship_layer = folium.map.FeatureGroup(name = \"Gulf of Finland\")\n",
    "    saimaa_laatokka_ship_layer = folium.map.FeatureGroup(name = \"Saimaa and Laatokka\", show = False)\n",
    "    vip_ship_layer             = folium.map.FeatureGroup(name = \"VIP ships\")\n",
    "\n",
    "    for ship in ships_df.itertuples(index=False, name='Ship'):\n",
    "        color = \"#8ed6ff\"\n",
    "        if(ship.mmsi in vip_ships):\n",
    "            color = \"#26f018\"\n",
    "        iframe = folium.IFrame(html=ship.tooltip_html, width=300, height=350)\n",
    "        popup = folium.Popup(html=iframe, max_width=300)\n",
    "        marker = plugins.BoatMarker([ship.latitude, ship.longitude], popup=popup, color=color,\n",
    "                                     heading=ship.cog, pathCoords=ship.path, circleRadius=ship.range)\n",
    "        if(ship.mmsi in vip_ships):\n",
    "            marker.add_to(vip_ship_layer)\n",
    "        elif(ship.shipRegion == \"Bothnian Bay\"):\n",
    "            marker.add_to(bothnian_bay_ship_layer)\n",
    "        elif(ship.shipRegion == \"Bothnian Sea\"):\n",
    "            marker.add_to(bothnian_sea_ship_layer)    \n",
    "        elif(ship.shipRegion == \"Archipelago Sea\"):\n",
    "            marker.add_to(archipelago_sea_ship_layer)\n",
    "        elif(ship.shipRegion == \"Gulf of Finland\"):\n",
    "            marker.add_to(gulf_of_finland_ship_layer)\n",
    "        elif(ship.shipRegion == \"Saimaa and Laatokka\"):\n",
    "            marker.add_to(saimaa_laatokka_ship_layer)\n",
    "        else:\n",
    "            marker.add_to(baltic_sea_ship_layer)\n",
    "\n",
    "    # Add the layers to the map\n",
    "    baltic_sea_ship_layer.add_to(map)\n",
    "    bothnian_bay_ship_layer.add_to(map)\n",
    "    bothnian_sea_ship_layer.add_to(map)\n",
    "    archipelago_sea_ship_layer.add_to(map)\n",
    "    gulf_of_finland_ship_layer.add_to(map)\n",
    "    saimaa_laatokka_ship_layer.add_to(map)\n",
    "    vip_ship_layer.add_to(map)\n",
    "\n",
    "    # Add links to ant-path and semi-circle js for on-click effects to work\n",
    "    link = folium.JavascriptLink(\"https://cdn.jsdelivr.net/npm/leaflet-ant-path@1.3.0/dist/leaflet-ant-path.js\")\n",
    "    map.get_root().html.add_child(link)\n",
    "\n",
    "    link = folium.JavascriptLink(\"https://cdn.jsdelivr.net/npm/leaflet-semicircle@2.0.4/Semicircle.min.js\")\n",
    "    map.get_root().html.add_child(link)\n",
    "\n",
    "    return map\n",
    "\n",
    "def add_on_click_functionality(map):\n",
    "    '''Edit javascript to add on-click events to ship markers'''\n",
    "\n",
    "    # Modify Marker template to include the onClick event\n",
    "    \n",
    "    click_template = \"\"\"\n",
    "                    {% macro script(this, kwargs) %}\n",
    "                        var {{ this.get_name() }} = L.boatMarker(\n",
    "                            {{ this.location|tojson }},\n",
    "                            {{ this.options|tojson }}\n",
    "                        ).addTo({{ this._parent.get_name() }}).on('click', onClick).on('dblclick', onDblClick);\n",
    "                        {% if this.wind_heading is not none -%}\n",
    "                        {{ this.get_name() }}.setHeadingWind(\n",
    "                            {{ this.heading }},\n",
    "                            {{ this.wind_speed }},\n",
    "                            {{ this.wind_heading }}\n",
    "                        );\n",
    "                        {% else -%}\n",
    "                        {{this.get_name()}}.setHeading({{this.heading}});\n",
    "                        {% endif -%}\n",
    "                    {% endmacro %}\n",
    "                    \"\"\"\n",
    "\n",
    "    # Change template to custom template\n",
    "    plugins.BoatMarker._template = folium.map.Template(click_template)\n",
    "\n",
    "    map_id = map.get_name()\n",
    "\n",
    "    # Extensions of circle and polyline are used here so they can be removed on click without \n",
    "    # removing all circles and polylines (glider paths and ranges)\n",
    "    click_js = f\"\"\"function onClick(e) {{                \n",
    "                                    \n",
    "                    var coords = e.target.options.pathCoords;\n",
    "\n",
    "                    var circle_radius = e.target.options.circleRadius;\n",
    "                    var ship_location = [e.latlng.lat, e.latlng.lng];\n",
    "\n",
    "\n",
    "                    var ship_range = L.semiCircle(ship_location, {{\n",
    "                    radius: circle_radius,\n",
    "                    fill: true,\n",
    "                    color: 'red',\n",
    "                    fillColor: 'orange',\n",
    "                    fillOpacity: 0.3,\n",
    "                    startAngle: 360,\n",
    "                    stopAngle: 360\n",
    "\n",
    "                    }}).on('dblclick', onDblClick);\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    var ant_path = L.polyline.antPath(coords, {{\n",
    "                    \"delay\": 400,\n",
    "                    \"dashArray\": [\n",
    "                        10,\n",
    "                        20\n",
    "                    ],\n",
    "                    \"weight\": 5,\n",
    "                    \"color\": \"#0000FF\",\n",
    "                    \"pulseColor\": \"#FFFFFF\",\n",
    "                    \"paused\": false,\n",
    "                    \"reverse\": false,\n",
    "                    \"hardwareAccelerated\": true\n",
    "                    }}); \n",
    "\n",
    "\n",
    "                    {map_id}.eachLayer(function(layer){{\n",
    "                    if (layer instanceof L.Polyline.AntPath)\n",
    "                        {{ {map_id}.removeLayer(layer) }}\n",
    "                        }});\n",
    "\n",
    "                    {map_id}.eachLayer(function(layer){{\n",
    "                    if (layer instanceof L.SemiCircle)\n",
    "                        {{ {map_id}.removeLayer(layer) }}\n",
    "                        }});\n",
    "\n",
    "                    ship_range.addTo({map_id});    \n",
    "                    ant_path.addTo({map_id});\n",
    "                    }}\n",
    "\n",
    "                    function onDblClick(e) {{\n",
    "                        {map_id}.eachLayer(function(layer){{\n",
    "                    if (layer instanceof L.SemiCircle)\n",
    "                        {{ {map_id}.removeLayer(layer) }}\n",
    "                        }});\n",
    "                    }}\n",
    "                    \"\"\"\n",
    "                    \n",
    "    e = folium.Element(click_js)\n",
    "    html = map.get_root()\n",
    "    html.script.add_child(e)\n",
    "     \n",
    "    return map\n",
    "\n",
    "def extrapolate_variables(glider_df, extrapolation_variables, extrapolation_targets):\n",
    "    # Calculate the differences between rows in datetime and battery_variable columns\n",
    "    gradient_df = glider_df[extrapolation_variables + [\"datetime\"]].diff()\n",
    "\n",
    "    last_datetime = glider_df[\"datetime\"].loc[glider_df[\"datetime\"].idxmax()]\n",
    "    extrapolated_data = pd.DataFrame([np.full(len(extrapolation_variables), np.nan)], columns=extrapolation_variables)\n",
    "    extrapolated_data = extrapolated_data.add_suffix(\"_extrapolated\")\n",
    "    extrapolated_data[\"datetime\"] = last_datetime\n",
    "\n",
    "    for i,variable in enumerate(extrapolation_variables):\n",
    "        extrapolation_target = extrapolation_targets[i]\n",
    "        # Calculate the difference per second for each row\n",
    "        gradient_df[f\"{variable}_per_second\"] = gradient_df[variable]/gradient_df[\"datetime\"].dt.seconds\n",
    "        # Take the average per second difference from rows within timeframe ending at last glider transmission\n",
    "        gradient_timeframe = timedelta(hours=12)\n",
    "        gradient_timeframe_idx = (glider_df[\"datetime\"] > max(glider_df[\"datetime\"]) - gradient_timeframe) & (gradient_df[f\"{variable}_per_second\"].notna())\n",
    "\n",
    "        if(len(gradient_timeframe_idx) > 0):\n",
    "            avg_gradient = np.average(gradient_df[gradient_timeframe_idx][f\"{variable}_per_second\"], \n",
    "                                      weights=gradient_df[gradient_timeframe_idx][\"datetime\"].dt.seconds)\n",
    "        else:\n",
    "            avg_gradient = np.nan\n",
    "\n",
    "        last_value = glider_df[variable].loc[glider_df[variable].last_valid_index()]\n",
    "        last_value_datetime = glider_df[\"datetime\"].loc[glider_df[variable].last_valid_index()]\n",
    "        \n",
    "        if(np.isnan(avg_gradient) | \n",
    "           (avg_gradient*(extrapolation_target-last_value) <= 0)): # Gradient == 0 or different sign from expected gradient\n",
    "            continue # Extrapolated values are NaN\n",
    "\n",
    "        secs_to_target = (extrapolation_target-last_value)/avg_gradient\n",
    "        secs_to_target = np.ceil(secs_to_target)\n",
    "\n",
    "        extrapolated_datetime = last_value_datetime + timedelta(seconds=secs_to_target)\n",
    "        extrapolated_value = last_value + secs_to_target*avg_gradient\n",
    "\n",
    "        # Add the starting point for the extrapolated graph\n",
    "        if(extrapolated_data.datetime.isin([last_value_datetime]).any()): # If startpoint datetime already in dataframe\n",
    "            extrapolated_data.loc[extrapolated_data[\"datetime\"] == last_value_datetime, f\"{variable}_extrapolated\"] = last_value\n",
    "        else: # If endpoint datetime not yet in dataframe\n",
    "            new_row = {\"datetime\":last_value_datetime, f\"{variable}_extrapolated\":last_value}\n",
    "            extrapolated_data = pd.concat([extrapolated_data, pd.DataFrame([new_row])], ignore_index=True)\n",
    "            \n",
    "        # Add the end point for the extrapolated graph\n",
    "        if(extrapolated_data.datetime.isin([extrapolated_datetime]).any()): # If endpoint datetime already in dataframe\n",
    "            extrapolated_data.loc[extrapolated_data[\"datetime\"] == extrapolated_datetime, f\"{variable}_extrapolated\"] = extrapolated_value\n",
    "        else: # If endpoint datetime not yet in dataframe\n",
    "            new_row = {\"datetime\":extrapolated_datetime, f\"{variable}_extrapolated\":extrapolated_value}\n",
    "            extrapolated_data = pd.concat([extrapolated_data, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    \n",
    "    # Since Altair has issues with columns that are mostly missing values, we need to extrapolate all variables to the last datetime\n",
    "    extrapolated_data.sort_values(by=[\"datetime\"], inplace=True)\n",
    "    extrapolated_data.set_index(\"datetime\", inplace=True)\n",
    "    extrapolated_data.interpolate(method='time', inplace=True, limit_direction=\"forward\", limit_area=\"inside\")\n",
    "    extrapolated_data.reset_index(inplace=True)\n",
    "\n",
    "    return extrapolated_data\n",
    "\n",
    "def extrapolate_glider_battery(glider_name, glider_df, interesting_sensors):\n",
    "    '''Extrapolate glider battery level for plotting'''\n",
    "    # If the glider is named Koskelo, use m_lithium_battery_relative_charge. Otherwise m_battery\n",
    "    battery_variable = \"m_battery\"\n",
    "    battery_unit = \"V\"\n",
    "    battery_extrapolation_target = 10\n",
    "    battery_domain = [battery_extrapolation_target,16]\n",
    "    \n",
    "    if(glider_name == \"Koskelo\"): \n",
    "        battery_variable = \"m_lithium_battery_relative_charge\"\n",
    "        battery_unit = \"%\"\n",
    "        battery_extrapolation_target = 10\n",
    "        battery_domain = [battery_extrapolation_target, 100]   \n",
    "\n",
    "    coulomb_extrapolation_target = 160\n",
    "    coulomb_domain = [0, coulomb_extrapolation_target]\n",
    "\n",
    "    extrapolation_variables = [battery_variable, \"m_coulomb_amphr_total\"]\n",
    "    extrapolation_targets = [battery_extrapolation_target, coulomb_extrapolation_target]\n",
    "\n",
    "    extrapolated_data = extrapolate_variables(glider_df, extrapolation_variables, extrapolation_targets)\n",
    "\n",
    "    # Create the dataframe used in plotting\n",
    "    plot_df = glider_df[[\"datetime\"]+interesting_sensors].copy()\n",
    "    plot_df = plot_df.merge(extrapolated_data, how=\"outer\")\n",
    "\n",
    "    return plot_df, battery_variable, battery_unit, battery_domain, coulomb_domain\n",
    "\n",
    "def adjust_domains(domain, end_point_values):\n",
    "    '''Adjust domain ranges based on last and first two values'''\n",
    "    # If non-outlier end point value is outside domain, then expand domain\n",
    "    # Check domain minimum\n",
    "    if(abs(end_point_values[0] - end_point_values[1]) < 1): # If neither is an outlier\n",
    "        if(min(end_point_values[0:2]) < domain[0]): # If the smaller value is smaller than domain minimum\n",
    "            domain[0] = min(end_point_values[0:2])\n",
    "    else:                                           # If one is an outlier\n",
    "        if(max(end_point_values[0:2]) < domain[0]): # If the larger value is smaller than domain minimum\n",
    "            domain[0] = max(end_point_values[0:2])  \n",
    "\n",
    "    # Check domain maximum\n",
    "    if(abs(end_point_values[2] - end_point_values[3]) < 1): # If neither is an outlier\n",
    "        if(max(end_point_values[2:4]) > domain[1]): # If the larger value is larger than domain minimum\n",
    "            domain[1] = max(end_point_values[2:4])\n",
    "    else:                                           # If one is an outlier\n",
    "        if(min(end_point_values[2:4]) > domain[1]): # If the smaller value is larger than domain minimum\n",
    "            domain[1] = min(end_point_values[2:4])\n",
    "    \n",
    "    return domain\n",
    "\n",
    "def adjust_glider_popup_chart_domains(glider_df, battery_variable, battery_domain, coulomb_domain):\n",
    "    '''Make sure all relevant glider data gets shown'''\n",
    "    # battery_variable\n",
    "    highest_battery_value_index = glider_df[battery_variable].first_valid_index()\n",
    "    second_highest_battery_value_index = glider_df[battery_variable].loc[highest_battery_value_index+1:].first_valid_index()\n",
    "\n",
    "    lowest_battery_value_index = glider_df[battery_variable].last_valid_index()\n",
    "    second_lowest_battery_value_index = glider_df[battery_variable].loc[:lowest_battery_value_index-1].last_valid_index()\n",
    "\n",
    "    battery_end_values = glider_df[battery_variable].loc[[lowest_battery_value_index, second_lowest_battery_value_index, \n",
    "                                                          second_highest_battery_value_index, highest_battery_value_index]].tolist()\n",
    "\n",
    "    battery_domain = adjust_domains(battery_domain, battery_end_values)\n",
    "\n",
    "    # m_coulomb_amphr_total\n",
    "    highest_coulomb_value_index = glider_df[\"m_coulomb_amphr_total\"].last_valid_index()\n",
    "    second_highest_coulomb_value_index = glider_df[\"m_coulomb_amphr_total\"].loc[:highest_coulomb_value_index-1].last_valid_index()\n",
    "\n",
    "    lowest_coulomb_value_index = glider_df[\"m_coulomb_amphr_total\"].first_valid_index()\n",
    "    second_lowest_coulomb_value_index = glider_df[\"m_coulomb_amphr_total\"].loc[lowest_coulomb_value_index+1:].first_valid_index()\n",
    "\n",
    "    coulomb_end_values = glider_df[\"m_coulomb_amphr_total\"].loc[[lowest_coulomb_value_index, second_lowest_coulomb_value_index, \n",
    "                                                          second_highest_coulomb_value_index, highest_coulomb_value_index]].tolist()\n",
    "\n",
    "    coulomb_domain = adjust_domains(coulomb_domain, coulomb_end_values)\n",
    "\n",
    "    return battery_domain, coulomb_domain\n",
    "\n",
    "def create_glider_popup_chart(glider_name, glider_df, interesting_sensors):\n",
    "    '''Create the chart used in glider popup'''\n",
    "    plot_df, battery_variable, battery_unit, battery_domain, coulomb_domain = extrapolate_glider_battery(glider_name, glider_df, interesting_sensors)\n",
    "\n",
    "    date_range = [min(glider_df.datetime),max(glider_df.datetime)]\n",
    "    battery_domain, coulomb_domain = adjust_glider_popup_chart_domains(glider_df, battery_variable, battery_domain, coulomb_domain)\n",
    "\n",
    "    # Create the base chart we will add more to\n",
    "    # This allows added charts to share axes and/or interactivity\n",
    "    base = alt.Chart(plot_df).encode(\n",
    "        alt.X('datetime:T', timeUnit='yearmonthdatehoursminutes').axis(title=None).scale(domain=date_range)\n",
    "    ).properties(\n",
    "        width=300,\n",
    "        height=300\n",
    "    ).interactive()\n",
    "\n",
    "    # Create the chart for battery level\n",
    "    battery = base.mark_line().encode(\n",
    "        alt.Y(f'{battery_variable}:Q').title(f'{battery_variable} ({battery_unit})').scale(domain=battery_domain),\n",
    "    )\n",
    "    battery_extrapolated = base.mark_line(color=\"red\").encode(\n",
    "        alt.Y(f'{battery_variable}_extrapolated:Q').title(''),\n",
    "    )\n",
    "    total_battery = alt.layer(battery, battery_extrapolated)\n",
    "\n",
    "    # Create the chart for leakage\n",
    "    leak = base.mark_line().encode( #, interpolate='monotone'\n",
    "        alt.Y('m_digifin_leakdetect_reading:Q').title('m_digifin_leakdetect_reading').scale(zero=False)\n",
    "    )\n",
    "\n",
    "     # Create the chart for m_coulomb_amphr_total\n",
    "    coulomb = base.mark_line().encode(\n",
    "        alt.Y('m_coulomb_amphr_total:Q').title('m_coulomb_amphr_total (Ah)').scale(domain=coulomb_domain)\n",
    "    )\n",
    "    coulomb_extrapolated = base.mark_line(color=\"red\").encode(\n",
    "        alt.Y('m_coulomb_amphr_total_extrapolated:Q').title(''),\n",
    "    )\n",
    "    total_coulomb = alt.layer(coulomb, coulomb_extrapolated)\n",
    "\n",
    "    # Combine the charts\n",
    "    chart = (total_battery | leak | total_coulomb).properties(\n",
    "        title=f\"{glider_name}\",\n",
    "        autosize=\"pad\",\n",
    "        padding={\"left\": 20, \"top\": 5, \"right\": 20, \"bottom\": 10}\n",
    "    ).configure_title(\n",
    "        fontSize=24\n",
    "    )\n",
    "    return chart\n",
    "\n",
    "def add_glider_markers(map, glider_data, interesting_sensors):\n",
    "    '''Add markers for gliders on the map'''\n",
    "\n",
    "    glider_names       = glider_data[\"glider_names\"]\n",
    "    gliders_df         = glider_data[\"gliders_df\"]\n",
    "    gliders_wpt_df     = glider_data[\"gliders_wpt_df\"]\n",
    "    gliders_latest_loc = glider_data[\"gliders_latest_loc\"]\n",
    "\n",
    "    for glider_name in glider_names:\n",
    "        glider_df = gliders_df.loc[gliders_df[\"glider_name\"] == glider_name]\n",
    "        glider_path = glider_df[[\"latitude\", \"longitude\"]].values.tolist()\n",
    "\n",
    "        glider_latest_loc = gliders_latest_loc[[\"latitude\", \"longitude\"]].loc[gliders_latest_loc[\"glider_name\"] == glider_name].values.tolist()[0]\n",
    "\n",
    "        glider_wpt_df = gliders_wpt_df.loc[gliders_wpt_df[\"glider_name\"] == glider_name]\n",
    "        glider_wpts = glider_wpt_df[[\"latitude\", \"longitude\"]].values.tolist()\n",
    "\n",
    "        # For some reason multiple markers can't point to the same CustomIcon, so this needs to be inside the loop\n",
    "        glider_icon = folium.CustomIcon(\n",
    "            \"http://nodc.fmi.fi/uivelo/icons/slocum-icon.png\",\n",
    "            icon_size=(50, 27),\n",
    "            icon_anchor=(25, 13)\n",
    "        )\n",
    "\n",
    "        glider_marker = folium.Marker(\n",
    "            location=glider_latest_loc, icon=glider_icon\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            chart = create_glider_popup_chart(glider_name, glider_df, interesting_sensors)\n",
    "        except (KeyError, ZeroDivisionError) as e: # Handle missing data\n",
    "            print(e)\n",
    "            popup = folium.Popup(glider_name).add_to(glider_marker)\n",
    "        else:\n",
    "            popup = folium.Popup(glider_name).add_to(glider_marker)\n",
    "            folium.VegaLite(chart).add_to(popup)\n",
    "\n",
    "        glider_marker.add_to(map)\n",
    "\n",
    "        folium.Circle(\n",
    "            location=glider_latest_loc,\n",
    "            radius=3000,\n",
    "            color=\"red\",\n",
    "            fill_color=\"orange\",\n",
    "            fillOpacity=0.3,\n",
    "            popup=\"3 km range\"\n",
    "        ).add_to(map)\n",
    "\n",
    "        if(len(glider_path) > 0):\n",
    "            folium.PolyLine(glider_path, popup=f\"{glider_name}'s path\", tooltip=None, color='red').add_to(map)\n",
    "\n",
    "        if(len(glider_wpts) == 1):\n",
    "            folium.PolyLine([glider_latest_loc]+glider_wpts, popup=f\"{glider_name}'s current plan\", tooltip=None).add_to(map)\n",
    "        elif(len(glider_wpts) > 1):\n",
    "            folium.PolyLine(glider_wpts, popup=f\"{glider_name}'s current plan\", tooltip=None).add_to(map)\n",
    "\n",
    "    return map\n",
    "\n",
    "def add_ship_markers(map, ships_df):\n",
    "    '''Add markers for ships on the map'''\n",
    "\n",
    "    # Create layers for ship markers\n",
    "    uncategorized_ship_layer      = folium.map.FeatureGroup(name = \"Uncategorized Ships\", show = False)\n",
    "    stationary_ships_layer        = folium.map.FeatureGroup(name = \"Stationary ships\", show = False) # Default off, mostly just unnecessary clutter at harbours\n",
    "    region_sharing_ships_layer    = folium.map.FeatureGroup(name = \"Region sharing ships\") # Ships that are - or have a destination to go to - in gliders' regions\n",
    "    within_range_ships_layer      = folium.map.FeatureGroup(name = \"Within range ships\")\n",
    "    path_intersecting_ships_layer = folium.map.FeatureGroup(name = \"Path intersecting ships\")\n",
    "    very_close_ships_layer        = folium.map.FeatureGroup(name = \"Very close ships\")\n",
    "    vip_ships_layer               = folium.map.FeatureGroup(name = \"VIP ships\")\n",
    "\n",
    "    for ship in ships_df.itertuples(index=False, name='Ship'):\n",
    "        iframe = folium.IFrame(html=ship.tooltip_html, width=300, height=350)\n",
    "        popup = folium.Popup(html=iframe, max_width=300)\n",
    "        marker = plugins.BoatMarker([ship.latitude, ship.longitude], popup=popup, \n",
    "                           heading=ship.cog, pathCoords=ship.path, circleRadius=ship.range, \n",
    "                           color=ship.max_class_colour)\n",
    "        \n",
    "        if(ship.max_class_colour == \"yellow\"):\n",
    "            marker.add_to(region_sharing_ships_layer)\n",
    "        elif(ship.max_class_colour == \"orange\"):\n",
    "            marker.add_to(path_intersecting_ships_layer)    \n",
    "        elif(ship.max_class_colour == \"red\"):\n",
    "            marker.add_to(within_range_ships_layer)\n",
    "        elif(ship.max_class_colour == \"grey\"):\n",
    "            marker.add_to(stationary_ships_layer)\n",
    "        elif(ship.max_class_colour == \"purple\"):\n",
    "            marker.add_to(very_close_ships_layer)\n",
    "        elif(ship.max_class_colour == \"#26f018\"):\n",
    "            marker.add_to(vip_ships_layer)\n",
    "        else:\n",
    "            marker.add_to(uncategorized_ship_layer)\n",
    "\n",
    "    # Add the layers to the map\n",
    "    uncategorized_ship_layer.add_to(map)\n",
    "    stationary_ships_layer.add_to(map)\n",
    "    region_sharing_ships_layer.add_to(map)\n",
    "    within_range_ships_layer.add_to(map)\n",
    "    path_intersecting_ships_layer.add_to(map)\n",
    "    very_close_ships_layer.add_to(map)\n",
    "    vip_ships_layer.add_to(map)\n",
    "\n",
    "    # Add links to ant-path and semi-circle js for on-click effects to work\n",
    "    link = folium.JavascriptLink(\"https://cdn.jsdelivr.net/npm/leaflet-ant-path@1.3.0/dist/leaflet-ant-path.js\")\n",
    "    map.get_root().html.add_child(link)\n",
    "\n",
    "    link = folium.JavascriptLink(\"https://cdn.jsdelivr.net/npm/leaflet-semicircle@2.0.4/Semicircle.min.js\")\n",
    "    map.get_root().html.add_child(link)\n",
    "    return map\n",
    "\n",
    "def add_aranda_plan(map):\n",
    "    try:\n",
    "        aranda_df = pd.read_csv(\"../Map Data/waterexchange.csv\")\n",
    "    except HTTPError:\n",
    "        return\n",
    "\n",
    "    # Strip object-type columns (string columns) of excess whitespace\n",
    "    aranda_df_obj = aranda_df.select_dtypes(['object'])\n",
    "    aranda_df[aranda_df_obj.columns] = aranda_df_obj.apply(lambda x: x.str.strip())\n",
    "    # Drop duplicate rows (excluding decimal degree coordinates since floating point errors in conversions)\n",
    "    aranda_df = aranda_df[~aranda_df.drop([\"latitude\", \"longitude\"], axis=1).duplicated()]\n",
    "    # aranda_df = aranda_df[~aranda_df[\"Index\"].duplicated()]\n",
    "\n",
    "    aranda_df[\"Datetime\"] = aranda_df.apply(lambda row: datetime(int(row[\"Date\"][-4:]), int(row[\"Date\"][3:5]), int(row[\"Date\"][0:2]), int(row[\"Time\"]), int(100*(row[\"Time\"]-int(row[\"Time\"])))), axis=1)\n",
    "    aranda_df[\"Deg_coords\"] = aranda_df[\"Lat\"] + \"N \" + aranda_df[\"Long\"] + \"E\"\n",
    "    \n",
    "    aranda_stations_layer = folium.map.FeatureGroup(name = \"Aranda stations\", show = False)\n",
    "    \n",
    "    # List all indexes per station\n",
    "    stations_df = aranda_df[~aranda_df[\"Deg_coords\"].duplicated()]\n",
    "    station_indexes = aranda_df.groupby('Deg_coords')['Index'].apply(lambda x: \n",
    "                                                                  ', '.join(str(index) for index in list(x))).copy()\n",
    "    station_indexes.name = \"Index_html_string\"\n",
    "    stations_df = stations_df.merge(station_indexes, left_on=\"Deg_coords\", right_index=True, how=\"left\")\n",
    "\n",
    "    # List all datetimes per station\n",
    "    station_datetimes = aranda_df.groupby('Deg_coords')['Datetime'].apply(lambda x: \n",
    "                                                                  '<br>'.join(str(index) for index in list(x))).copy()\n",
    "    station_datetimes.name = \"Datetime_html_string\"\n",
    "    stations_df = stations_df.merge(station_datetimes, left_on=\"Deg_coords\", right_index=True, how=\"left\")\n",
    "\n",
    "\n",
    "    stations_df['tooltip_html'] = stations_df.apply(lambda station: '</span></p><p style=\"text-align:left;\">'.join(\n",
    "                ['<p style=\"text-align:left;\"> ' + \n",
    "                'Station: <span style=\"float:right;\">'    + str(station['Station']),\n",
    "                'Station Nr: <span style=\"float:right;\">' + station['Index_html_string'],\n",
    "                'When: <span style=\"float:right;\">' + station['Datetime_html_string'] + \n",
    "                '</span></p>']), axis=1)\n",
    "\n",
    "    for station in stations_df.itertuples(index=False, name='Ship'):\n",
    "        iframe = folium.IFrame(html=station.tooltip_html, width=220, height=120)\n",
    "        popup = folium.Popup(html=iframe, max_width=220)\n",
    "        folium.CircleMarker([station.latitude, station.longitude], popup=popup, color=\"green\").add_to(aranda_stations_layer)\n",
    "\n",
    "    folium.PolyLine(aranda_df[[\"latitude\", \"longitude\"]].values.tolist(), popup=\"Aranda's current plan\", color=\"green\", opacity=0.3).add_to(aranda_stations_layer)\n",
    "    aranda_stations_layer.add_to(map)\n",
    "\n",
    "    return map\n",
    "\n",
    "def add_markers(map, ships_df, glider_data, interesting_sensors):\n",
    "\n",
    "    map = add_glider_markers(map, glider_data, interesting_sensors)\n",
    "    map = add_ship_markers(map, ships_df)\n",
    "    map = add_aranda_plan(map)\n",
    "\n",
    "    return map\n",
    "\n",
    "def add_tile_layers(map):\n",
    "    '''Add tile layers to the map'''\n",
    "\n",
    "    # Default base map\n",
    "    # Normally \"tiles\" and \"name\" parameters would be enough, but since we want custom attribution...\n",
    "    folium.TileLayer(tiles='https://tile.openstreetmap.org/{z}/{x}/{y}.png', #tiles='openstreetmap',\n",
    "                     name='OpenStreetMap',\n",
    "                     max_zoom = 19,\n",
    "                     overlay=False,\n",
    "                     attr='Data by: Fintraffic / digitraffic.fi, license CC 4.0 BY, &copy; <a href=\"https://www.openstreetmap.org/copyright\">OpenStreetMap</a> contributors').add_to(map)\n",
    "\n",
    "    # Alternate base map from bathymetry data\n",
    "    bathymetry_layer = folium.map.FeatureGroup(name = \"EMODNET Bathymetry and coast lines\", overlay = False, show=False)\n",
    "\n",
    "    folium.WmsTileLayer(url = \"https://ows.emodnet-bathymetry.eu/wms\", \n",
    "                        layers=\"mean_atlas_land\", \n",
    "                        fmt=\"image/png\",\n",
    "                        attr='Data by: Fintraffic / digitraffic.fi, license CC 4.0 BY, EMODnet-Bathymetry', \n",
    "                        name=\"EMODNET Bathymetry\", \n",
    "                        overlay=False).add_to(bathymetry_layer)\n",
    "    \n",
    "    folium.WmsTileLayer(url = \"https://ows.emodnet-bathymetry.eu/wms\", \n",
    "                        layers=\"coastlines\", \n",
    "                        fmt=\"image/png\",\n",
    "                        attr='Data by: Fintraffic / digitraffic.fi, license CC 4.0 BY, EMODnet-Bathymetry', \n",
    "                        name=\"EMODNET coast lines\", \n",
    "                        transparent = True).add_to(bathymetry_layer)\n",
    "    \n",
    "    bathymetry_layer.add_to(map)\n",
    "    \n",
    "    # Overlay for sea marks\n",
    "    folium.TileLayer(tiles = \"http://t1.openseamap.org/seamark/{z}/{x}/{y}.png\", \n",
    "                     name = \"OpenSeaMap\", \n",
    "                     min_zoom = 8, \n",
    "                     max_zoom = 14,\n",
    "                     overlay = True,\n",
    "                     attr = '&copy; <a href=\"http://www.openseamap.org\">OpenSeaMap</a> contributors').add_to(map)\n",
    "    \n",
    "    # Overlay for fishing ship traffic density, default off\n",
    "    folium.WmsTileLayer(url = \"https://ows.emodnet-humanactivities.eu/geoserver/emodnet/ows?service=WMS\", \n",
    "                        layers=\"emodnet:vesseldensity_01avg\", \n",
    "                        fmt=\"image/png\",\n",
    "                        transparent = True,\n",
    "                        attr='EMODNET-Human Activities and CLS', \n",
    "                        maxZoom = 20,\n",
    "                        minZoom = 3,\n",
    "                        show=False,\n",
    "                        name=\"EMODNET Fishing vessel traffic density\").add_to(map)\n",
    "    \n",
    "    # Overlay for passenger ship traffic density, default off\n",
    "    folium.WmsTileLayer(url = \"https://ows.emodnet-humanactivities.eu/geoserver/emodnet/ows?service=WMS\", \n",
    "                        layers=\"emodnet:vesseldensity_08avg\", \n",
    "                        fmt=\"image/png\",\n",
    "                        transparent = True,\n",
    "                        attr='EMODNET-Human Activities and CLS', \n",
    "                        maxZoom = 20,\n",
    "                        minZoom = 3,\n",
    "                        show=False,\n",
    "                        name=\"EMODNET Passenger vessel traffic density\").add_to(map)\n",
    "    \n",
    "    # Overlay for cargo ship traffic density, default off\n",
    "    folium.WmsTileLayer(url = \"https://ows.emodnet-humanactivities.eu/geoserver/emodnet/ows?service=WMS\", \n",
    "                        layers=\"emodnet:vesseldensity_09avg\", \n",
    "                        fmt=\"image/png\",\n",
    "                        transparent = True,\n",
    "                        attr='EMODNET-Human Activities and CLS', \n",
    "                        maxZoom = 20,\n",
    "                        minZoom = 3,\n",
    "                        show=False,\n",
    "                        name=\"EMODNET Cargo vessel traffic density\").add_to(map)\n",
    "\n",
    "    # Overlay for EEZ boundaries\n",
    "    folium.WmsTileLayer(url = \"http://geo.vliz.be/geoserver/MarineRegions/wms?\", \n",
    "                        layers = \"eez_boundaries\",\n",
    "                        fmt=\"image/png\", \n",
    "                        transparent=True, \n",
    "                        attr='Marineregions.org', \n",
    "                        name=\"EEZ\",\n",
    "                        opacity=0.10).add_to(map)\n",
    "\n",
    "    # Overlay for Finnish navigation charts (default to off due to low transparency)\n",
    "    folium.WmsTileLayer(url = \"https://julkinen.traficom.fi/s57/wms\", \n",
    "                        layers = \"cells\",\n",
    "                        attr=\"--- Navigation Chart service based on Liikennevirasto's raster data. Permit CC 4.0\" +\n",
    "                             \" Source: Liikennevirasto. Not for navigation. Does not fill quality of official navigation charts.\", \n",
    "                        name = \"Navigation chart\",\n",
    "                        transparent=True,\n",
    "                        show=False,\n",
    "                        fmt=\"image/png\",\n",
    "                        min_zoom = 7).add_to(map)\n",
    "    \n",
    "    return map\n",
    "\n",
    "def add_deployment_info(map):\n",
    "    '''Add an info text box showing glider deployment times'''\n",
    "    deployment_positions = read_json('../Map Data/Gliders/JSONs/deployment_positions.json')\n",
    "    glider_names = list(deployment_positions.keys())\n",
    "\n",
    "    deployment_html = \"\"\"\n",
    "            <p style=\"padding: 0px; margin: 0px;text-align:left;\">\"\"\"\n",
    "    for glider_name in glider_names:\n",
    "        deployment_html += f\"\"\"\n",
    "                {str.capitalize(glider_name)} deployed: &nbsp \n",
    "                    <span style=\"float:right;\"> {deployment_positions[glider_name][\"datetime\"]} </span><br>\"\"\"\n",
    "\n",
    "    deployment_html = deployment_html.rstrip(deployment_html[-4]) # Remove last (extra) linebreak\n",
    "    deployment_html += \"\"\"\n",
    "            </p>\"\"\"\n",
    "\n",
    "    # Injecting custom css through branca macro elements and template, give it a name\n",
    "    textbox_css = f\"\"\"\n",
    "    {{% macro html(this, kwargs) %}}\n",
    "\n",
    "        <div id=\"textbox\" class=\"textbox\">\n",
    "        <div class=\"textbox-title\">FMI glider missions</div>\n",
    "        <div class=\"textbox-content\">\n",
    "            {deployment_html}\n",
    "        </div>\n",
    "        </div>\n",
    "\n",
    "\n",
    "    <style type='text/css'>\n",
    "    .textbox {{\n",
    "        position: absolute;\n",
    "        z-index:9999;\n",
    "        border-radius:4px;\n",
    "        background: rgba( 255, 255, 255, 0.7 );\n",
    "        //background: rgba( 28, 25, 56, 0.25 );\n",
    "        //box-shadow: 0 8px 32px 0 rgba( 31, 38, 135, 0.37 );\n",
    "        //backdrop-filter: blur( 4px );\n",
    "        //-webkit-backdrop-filter: blur( 4px );\n",
    "        //border: 4px solid rgba( 215, 164, 93, 0.2 );\n",
    "        padding: 10px;\n",
    "        font-size:14px;\n",
    "        right: 20px;\n",
    "        //bottom: 20px;\n",
    "        top: 20px;\n",
    "        color: blue;\n",
    "    }}\n",
    "    .textbox .textbox-title {{\n",
    "        color: darkblue;\n",
    "        text-align: center;\n",
    "        margin-bottom: 5px;\n",
    "        font-weight: bold;\n",
    "        font-size: 22px;\n",
    "        }}\n",
    "    </style>\n",
    "    {{% endmacro %}}\n",
    "    \"\"\"\n",
    "    # configuring the custom style (you can call it whatever you want)\n",
    "    my_custom_style = MacroElement()\n",
    "    my_custom_style._template = Template(textbox_css)\n",
    "\n",
    "    # Adding my_custom_style to the map\n",
    "    map.get_root().add_child(my_custom_style)\n",
    "\n",
    "    return map\n",
    "\n",
    "def add_map_tools(map):\n",
    "    '''Add interactive tools to the map'''\n",
    "\n",
    "    # Cursor coordinates, shown bottom right\n",
    "    plugins.MousePosition().add_to(map)\n",
    "\n",
    "    # Measure tool, bottom left\n",
    "    plugins.MeasureControl(primary_length_unit   = 'kilometers', \n",
    "                           secondary_length_unit = 'miles', \n",
    "                           primary_area_unit     = 'hectares', \n",
    "                           secondary_area_unit   = 'acres',\n",
    "                           completed_color       = 'red',\n",
    "                           active_color          = 'orange',\n",
    "                           position              = 'bottomright').add_to(map)\n",
    "\n",
    "    # Various drawing tools, top left\n",
    "    plugins.Draw(draw_options={\"polyline\": {\"shapeOptions\": {\"color\": \"red\"}}}).add_to(map)\n",
    "\n",
    "    # Fullscreen toggle, top left\n",
    "    plugins.Fullscreen().add_to(map)\n",
    "\n",
    "    # Controlling layers\n",
    "    folium.LayerControl(position='bottomleft').add_to(map)\n",
    "\n",
    "    return map\n",
    "\n",
    "def draw_map(map_center, ships_df, interesting_sensors, vip_ships, db_connection):\n",
    "    '''Draw interactive map based on AIS data'''\n",
    "    map = folium.Map(location=map_center, zoom_start=9, tiles=None)\n",
    "    map = add_on_click_functionality(map)\n",
    "\n",
    "    glider_data, interesting_sensors = load_glider_data(interesting_sensors)\n",
    "\n",
    "    if(glider_data == None):\n",
    "        # Still draw a map of ships if there's no active gliders\n",
    "        ships_df = process_no_gliders_ship_data(ships_df)\n",
    "        map = add_no_gliders_ship_markers(map, ships_df, vip_ships)\n",
    "        map = add_aranda_plan(map)\n",
    "    else:\n",
    "        # Re-center map on latest glider location update\n",
    "        gliders_df = glider_data[\"gliders_df\"]\n",
    "        latest_glider_latitude = gliders_df.loc[gliders_df[\"datetime\"].idxmax()][\"latitude\"]\n",
    "        latest_glider_longitude = gliders_df.loc[gliders_df[\"datetime\"].idxmax()][\"longitude\"]\n",
    "        map.location = [latest_glider_latitude, latest_glider_longitude]\n",
    "        \n",
    "        ships_df = process_ship_data(ships_df, glider_data, vip_ships, db_connection)   \n",
    "        map = add_markers(map, ships_df, glider_data, interesting_sensors)     \n",
    "\n",
    "    map = add_tile_layers(map)\n",
    "    map = add_map_tools(map)\n",
    "    map = add_deployment_info(map)\n",
    "\n",
    "    return map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only update missing meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" database = \"../Map Data/AIS.sqlite\"\n",
    "# Set cutoff for last known locations to draw (locations updated before will not be drawn)\n",
    "since = datetime.now() - timedelta(hours=12, minutes=0)\n",
    "since = math.floor(since.timestamp()*1000)\n",
    "\n",
    "# Set initial map center\n",
    "longitude = 23.29\n",
    "latitude = 59.837\n",
    "map_center = [latitude, longitude]\n",
    "\n",
    "interesting_sensors = [\"m_battery\", \"m_coulomb_amphr_total\", \"m_digifin_leakdetect_reading\", \"m_lithium_battery_relative_charge\"]\n",
    "# Aranda = 230145000\n",
    "vip_ships = [230145000]\n",
    "\n",
    "db_connection = create_connection(database)\n",
    "ships_df = load_data(db_connection, since) # NOTE: Assumes each ship only has one row in meta table\n",
    "\n",
    "map = draw_map(map_center, ships_df, interesting_sensors, vip_ships, db_connection)\n",
    "db_connection.close()\n",
    "\n",
    "map\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full AIS update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.Digitraffic_To_SQLite import collect_ships_locations, delete_old\n",
    "from math import floor as floor\n",
    "\n",
    "database = \"../Map Data/AIS.sqlite\"\n",
    "# Set cutoff for last known locations to draw (locations updated before will not be drawn)\n",
    "since = datetime.now() - timedelta(hours=12, minutes=0)\n",
    "since = math.floor(since.timestamp()*1000)\n",
    "\n",
    "# Set initial map center\n",
    "longitude = 23.29\n",
    "latitude = 59.837\n",
    "distance = 500\n",
    "map_center = [latitude, longitude]\n",
    "\n",
    "interesting_sensors = [\"m_battery\", \"m_coulomb_amphr_total\", \"m_digifin_leakdetect_reading\", \"m_lithium_battery_relative_charge\"]\n",
    "# Aranda = 230145000\n",
    "vip_ships = [230145000]\n",
    "\n",
    "db_connection = create_connection(database)\n",
    "update_meta_table(db_connection, get_latest_meta_update_timestamp(db_connection))\n",
    "\n",
    "locations_df = collect_ships_locations(latitude, longitude, distance, since)\n",
    "append_table(db_connection, locations_df, \"locations\")\n",
    "delete_duplicate_rows(db_connection, \"locations\", \", \".join(list(locations_df.columns))) # TODO: Detect and fix outliers\n",
    "\n",
    "# TODO: Set reasonable cutoff\n",
    "time_cutoff_dt = datetime.now() - timedelta(days=30)\n",
    "time_cutoff_ts = math.floor(time_cutoff_dt.timestamp()*1000)\n",
    "delete_old(db_connection, \"locations\", \"locUpdateTimestamp\", time_cutoff_ts)\n",
    "\n",
    "ships_df = load_data(db_connection, since) # NOTE: Assumes each ship only has one row in meta table\n",
    "\n",
    "map = draw_map(map_center, ships_df, interesting_sensors, vip_ships, db_connection)\n",
    "db_connection.close()\n",
    "\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing and development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = \"../Map Data/AIS.sqlite\"\n",
    "\n",
    "# since = datetime.now() - timedelta(days=30)\n",
    "since = pd.to_datetime(\"2023-11-11 00:00\", format=\"%Y-%m-%d %H:%M\")\n",
    "since = math.floor(since.timestamp()*1000)\n",
    "\n",
    "longitude = 23.29\n",
    "latitude = 59.837\n",
    "map_center = [latitude, longitude]\n",
    "\n",
    "\n",
    "interesting_sensors = [\"m_battery\", \"m_coulomb_amphr_total\", \"m_digifin_leakdetect_reading\", \"m_lithium_battery_relative_charge\"]\n",
    "# Aranda = 230145000\n",
    "vip_ships = [230145000]\n",
    "\n",
    "db_connection = create_connection(database)\n",
    "ships_df = load_data(db_connection, since) # NOTE: Assumes each ship only has one row in meta table\n",
    "\n",
    "map = draw_map(map_center, ships_df, interesting_sensors, vip_ships, db_connection)\n",
    "\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map.save(\"../Map Data/example_map.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = \"../Map Data/test.sqlite\"\n",
    "since = datetime.now() - timedelta(days=30)\n",
    "since = math.floor(since.timestamp()*1000)\n",
    "\n",
    "longitude = 23.29\n",
    "latitude = 59.837\n",
    "map_center = [latitude, longitude]\n",
    "\n",
    "\n",
    "interesting_sensors = [\"m_battery\", \"m_coulomb_amphr_total\", \"m_digifin_leakdetect_reading\", \"m_lithium_battery_relative_charge\"]\n",
    "# Aranda = 230145000\n",
    "vip_ships = [230145000]\n",
    "\n",
    "db_connection = create_connection(database)\n",
    "ships_df = load_data(db_connection, since) # NOTE: Assumes each ship only has one row in meta table\n",
    "\n",
    "map = draw_map(map_center, ships_df, interesting_sensors, vip_ships, db_connection)\n",
    "db_connection.close()\n",
    "\n",
    "map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
